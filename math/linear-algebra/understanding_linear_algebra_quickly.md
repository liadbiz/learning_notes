## 前言

作为一个半路出家从机械转到计算机的孩子，当学习现在热门的诸如数据分析，计算机视觉，机器学习，甚至一些基本的数学课程的时候，我都发现，当年靠刷卷子考了不错成绩的线性代数已经不够用了。事实上，我仍然知道如何做矩阵乘法，如何解线性方程组，如何求特征值，如何做正交化，如何求奇异值。但是当面对一个算法，我只知道怎么做，但是却无法理解为什么这么做之后就有这样的效果的时候，我知道是我还没有理解线性代数的一些基本概念。

于是，我花了大概一个学期的空闲时间重新复习了线性代数，这篇笔记是我看完[linear algebra done right](https://www.amazon.com/s/?ie=UTF8&keywords=linear+algebra+done+right&tag=googhydr-20&index=aps&hvadid=241625178462&hvpos=1t1&hvnetw=g&hvrand=9333974304308926802&hvpone=&hvptwo=&hvqmt=e&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9030938&hvtargid=kwd-362876195&ref=pd_sl_167uxxb5dc_e)，[linear algebra done wrong](https://www.math.brown.edu/~treil/papers/LADW/LADW.html)，[matrix analysis](https://www.math.brown.edu/~treil/papers/LADW/LADW.html)三本书和[这个](http://immersivemath.com/ila/)以及[这个](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)视频教程之后写下的总结，既包含了一些重要的理论证明，也有直观上的解释，如果对正在学习线性代数的同学有帮助那是再好不过了。如果发现我有写错的地方，麻烦留言指出以免误导更多人，如果你有不同的意见也欢迎留言和我讨论。

如果你没有上过线性代数的课，建议你先去看一遍书，对线性代数有一个基本的认识，因为我会不自觉的省略我觉得很容易看懂的东西或者我已经知道的细节。

## 基本知识

### 向量空间


### 矩阵的意义

### 线性方程组的解

### 可逆与相似

### 特征值与奇异值

### 行列式

## 矩阵分解

### 奇异值分解

###

## 矩阵计算
